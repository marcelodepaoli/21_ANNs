{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcelodepaoli/21_ANNs/blob/main/00_No%C3%A7%C3%B5es_b%C3%A1sicas_de_sintaxe_do_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6xOHM-VL4PF"
      },
      "source": [
        "#Noções básicas de sintaxe do Keras\n",
        "\n",
        "No TensorFlow 2.0 o Keras é a principal API. Vamos trabalhar em um projeto de regressão simples para entender os fundamentos da sintaxe do Keras e adição de camadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GUvo2dzL4PH"
      },
      "source": [
        "## Os dados\n",
        "\n",
        "Para aprender a sintaxe básica do Keras, usaremos um conjunto de dados falsos muito simples. Nas aulas subsequentes, focaremos em conjuntos de dados reais. Por enquanto, vamos nos concentrar na sintaxe do TensorFlow 2.0.\n",
        "\n",
        "Vamos supor que esses dados sejam medições de algumas pedras raras, com 2 recursos de medição e um preço de venda. Nosso objetivo final seria tentar prever o preço de venda de uma nova pedra preciosa que acabamos de extrair do solo, a fim de tentar definir um preço justo no mercado.\n",
        "\n",
        "### Carregando os Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WK8Xq1VL4PI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"drive/My Drive/Colab Notebooks/IA/21_ANNs\")\n",
        "os.listdir()"
      ],
      "metadata": {
        "id": "2XKFo5RrMWEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5qbo4fWL4PM"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('DATA/fake_reg.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCPRpAk3L4PM"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgnwyZ0vL4PO"
      },
      "source": [
        "### Explorando os dados\n",
        "\n",
        "Vamos dar uma checada rápida nos dados, devemos ver uma forte correlação entre as características e o \"preço\" deste dataset inventado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xIfNd65L4PP"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SV0uFvHgL4PP"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSuv1G__L4PX"
      },
      "source": [
        "Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bn64goe8L4PX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtmm231wL4PY"
      },
      "outputs": [],
      "source": [
        "# Convertendo o Pandas Dataframe em Numpy Arrays para utilização no Keras\n",
        "\n",
        "# Características (Features)\n",
        "X = df[['feature1','feature2']].values\n",
        "\n",
        "# Rótulo (Label)\n",
        "y = df['price'].values\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUSHvzMZL4PZ"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULrEBvxhL4Pa"
      },
      "outputs": [],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lukeKpiuL4Pa"
      },
      "outputs": [],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rg5WExj1L4Pb"
      },
      "outputs": [],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQbgdfQ3L4Pb"
      },
      "source": [
        "## Normalizando/dimensionando os dados\n",
        "\n",
        "Nós normalizamos/dimensionamos os dados das características (features).\n",
        "\n",
        "[Por que não precisamos dimensionar o rótulo (label)](https://stats.stackexchange.com/questions/111467/is-it-necessary-to-scale-the-target-value-in-addition-to-scaling-features-for-re)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCcFP3IcL4Pc"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hq6v22trL4Pc"
      },
      "outputs": [],
      "source": [
        "help(MinMaxScaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKhtwfb6L4Pc"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwt5BPRGL4Pd"
      },
      "outputs": [],
      "source": [
        "# Aviso: para evitar vazamento de dados do conjunto de teste, apenas ajustamos nosso scaler ao conjunto de treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0qKEQR9L4Pd"
      },
      "outputs": [],
      "source": [
        "scaler.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYO6ddXlL4Pd"
      },
      "outputs": [],
      "source": [
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GqFeS3mL4Pe"
      },
      "source": [
        "# Sintaxe TensorFlow 2.0\n",
        "\n",
        "\n",
        "## Opções de Importação\n",
        "\n",
        "Existem várias maneiras de importar o Keras através do Tensorflow (essa é uma escolha de estilo extremamente pessoal, use qualquer método de importação de sua preferência). Usaremos o método apresentado na **documentação oficial do TF**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xc4M7qc1L4Pe"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tW9X0DvYL4Pf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRq9mEqaL4Pf"
      },
      "outputs": [],
      "source": [
        "help(Sequential)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr8Xd0ObL4Pg"
      },
      "source": [
        "## Criando um modelo\n",
        "\n",
        "Existem duas maneiras de criar modelos por meio da API do TF 2 Keras: passar uma lista de camadas de uma só vez ou adicioná-las uma a uma.\n",
        "\n",
        "Vamos mostrar os dois métodos (cabe a você escolher qual método prefere)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QiAivqfL4Ph"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vtI_0NPL4Ph"
      },
      "source": [
        "### Modelo - como uma lista de camadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dax5pa1rL4Ph"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Dense(units=2),\n",
        "    Dense(units=2),\n",
        "    Dense(units=2)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoLSrVF0L4Pi"
      },
      "source": [
        "### Modelo - adicionando as camadas uma a uma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50av5wPXL4Pi"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(2))\n",
        "model.add(Dense(2))\n",
        "model.add(Dense(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ2BQbFbL4Pi"
      },
      "source": [
        "Vamos construir um modelo simples e, em seguida, compilá-lo definindo nosso solucionador (solver)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJ1mXPbBL4Pj"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(4,activation='relu'))\n",
        "model.add(Dense(4,activation='relu'))\n",
        "model.add(Dense(4,activation='relu'))\n",
        "\n",
        "# Nó de saída final\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='rmsprop',loss='mse')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A-rAa1yL4Pj"
      },
      "source": [
        "### Escolhendo um otimizador e função de perda\n",
        "\n",
        "Tenha em mente que tipo de problema você está tentando resolver:\n",
        "\n",
        "    # Para um problema de classificação multiclasse\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Para um problema de classificação binária\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Para um problema de regressão de erro quadrado médio\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='mse')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov275GHsL4Pj"
      },
      "source": [
        "# Treinando\n",
        "\n",
        "Abaixo estão algumas definições comuns que são necessárias conhecer (e entender) para utilizar corretamente o Keras:\n",
        "\n",
        "* Amostra (Sample): um elemento de um conjunto de dados.\n",
        "    * Exemplo: uma imagem é uma amostra em uma rede convolucional (convolutional network)\n",
        "    * Exemplo: um arquivo de áudio é uma amostra para um modelo de reconhecimento de fala\n",
        "\n",
        "* Lote (Batch): um conjunto de N amostras. As amostras em um lote são processadas de forma independente, em paralelo. Se estiver treinando, um lote resulta em apenas uma atualização para o modelo. Um lote geralmente aproxima a distribuição dos dados de entrada melhor do que uma única entrada. Quanto maior o lote, melhor a aproximação; no entanto, também é verdade que o lote levará mais tempo para ser processado e ainda resultará em apenas uma atualização. Para inferência (avaliar/prever), é recomendável escolher um tamanho de lote que seja o maior possível sem esgotar a memória (já que lotes maiores geralmente resultarão em avaliação/previsão mais rápida).\n",
        "\n",
        "* Época (Epoch): um corte arbitrário (cutoff), geralmente definido como \"uma passagem em todo o conjunto de dados\", usado para separar o treinamento em fases distintas, o que é útil para registro e avaliação periódica.\n",
        "\n",
        "* Ao usar **validation_data** ou **validation_split** com o método **fit** dos modelos Keras, a avaliação será executada no final de cada época (epoch).\n",
        "\n",
        "* Dentro do Keras, existe a possibilidade de se adicionar callbacks especificamente projetados para serem executados no final de uma época. Exemplos disso são as mudanças na taxa de aprendizado (learning rate changes) e o ponto de verificação do modelo (model checkpointing - saving)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YA5_TB08L4Pk"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train,y_train,epochs=250)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-9GanwrL4Pv"
      },
      "source": [
        "## Avaliação\n",
        "\n",
        "Vamos avaliar o desempenho do modelo em nosso conjunto de treinamento e nosso conjunto de teste. Podemos comparar esses dois desempenhos para verificar o overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYBXM35rL4Pw"
      },
      "outputs": [],
      "source": [
        "model.history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJg0nGhNL4Pw"
      },
      "outputs": [],
      "source": [
        "loss = model.history.history['loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "tcgXKufaL4Pw"
      },
      "outputs": [],
      "source": [
        "sns.lineplot(x=range(len(loss)),y=loss)\n",
        "plt.title(\"Training Loss per Epoch\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skqMkwuCL4Px"
      },
      "source": [
        "### Comparando a avaliação final (MSE) no conjunto de treinamento e no conjunto de teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f43eivsBL4Px"
      },
      "outputs": [],
      "source": [
        "model.metrics_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8y8Ji-OjL4Py"
      },
      "outputs": [],
      "source": [
        "training_score = model.evaluate(X_train,y_train,verbose=0)\n",
        "test_score = model.evaluate(X_test,y_test,verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkyO1cuKL4Py"
      },
      "outputs": [],
      "source": [
        "training_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51kCxDOaL4Py"
      },
      "outputs": [],
      "source": [
        "test_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX1VODSIL4Pz"
      },
      "source": [
        "### Avaliações Adicionais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tu1lXbCcL4Pz"
      },
      "outputs": [],
      "source": [
        "test_predictions = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzRutU6WL4Pz"
      },
      "outputs": [],
      "source": [
        "test_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNmLBhsxL4P0"
      },
      "outputs": [],
      "source": [
        "pred_df = pd.DataFrame(y_test,columns=['Test Y'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mST0mRY-L4P0"
      },
      "outputs": [],
      "source": [
        "pred_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wq2JdshQL4P0"
      },
      "outputs": [],
      "source": [
        "test_predictions = pd.Series(test_predictions.reshape(300,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bH7CKMhZL4P1"
      },
      "outputs": [],
      "source": [
        "test_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qN6wt8jdL4P1"
      },
      "outputs": [],
      "source": [
        "pred_df = pd.concat([pred_df,test_predictions],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctbeyswUL4P1"
      },
      "outputs": [],
      "source": [
        "pred_df.columns = ['Test Y','Model Predictions']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fg8zagSL4P2"
      },
      "outputs": [],
      "source": [
        "pred_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucl14XbrL4P2"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x='Test Y',y='Model Predictions',data=pred_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smernebpL4P2"
      },
      "outputs": [],
      "source": [
        "pred_df['Error'] = pred_df['Test Y'] - pred_df['Model Predictions']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vVgcRCPL4P2"
      },
      "outputs": [],
      "source": [
        "sns.displot(pred_df['Error'],bins=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fC9VbacRL4P3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error,mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZMKQqZZL4P3"
      },
      "outputs": [],
      "source": [
        "mean_absolute_error(pred_df['Test Y'],pred_df['Model Predictions'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tf7jue6yL4P3"
      },
      "outputs": [],
      "source": [
        "mean_squared_error(pred_df['Test Y'],pred_df['Model Predictions'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5e3h2N4L4P4"
      },
      "outputs": [],
      "source": [
        "# Essencialmente a mesma coisa, diferença apenas devido à precisão\n",
        "test_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YyO-C0zL4P4"
      },
      "outputs": [],
      "source": [
        "#RMSE\n",
        "test_score**0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2c83LmRL4P5"
      },
      "source": [
        "# Prevendo em dados novos\n",
        "\n",
        "E se víssemos uma nova pedra preciosa do chão? Qual deve ser o preço? Este procedimento é **exatamente** igual ao da previsão em novos dados de teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXdBgDSeL4P5"
      },
      "outputs": [],
      "source": [
        "# [[Feature1, Feature2]]\n",
        "new_gem = [[998,1000]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5ssijf1L4P6"
      },
      "outputs": [],
      "source": [
        "# Não esqueça de normalizar!\n",
        "scaler.transform(new_gem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQ_x7t8UL4P6"
      },
      "outputs": [],
      "source": [
        "new_gem = scaler.transform(new_gem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHkKmqjhL4P6"
      },
      "outputs": [],
      "source": [
        "model.predict(new_gem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ijLEtLuL4P7"
      },
      "source": [
        "## Salvando e carregando um modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPC4GS69L4P7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axaAicoLL4P7"
      },
      "outputs": [],
      "source": [
        "model.save('my_model.h5')  # cria um arquivo HDF5 com o nome 'my_model.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvB5ymGAL4P7"
      },
      "outputs": [],
      "source": [
        "later_model = load_model('my_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFZrjyvqL4P7"
      },
      "outputs": [],
      "source": [
        "later_model.predict(new_gem)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}