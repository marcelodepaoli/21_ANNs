{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcelodepaoli/21_ANNs/blob/main/02_Classifica%C3%A7%C3%A3o_com_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jFzOwkNzkCR"
      },
      "source": [
        "# Keras TF 2.0 - Projeto de Classificação\n",
        "\n",
        "Vamos explorar uma tarefa de classificação com a API do Keras API para TF 2.0\n",
        "\n",
        "## Os dados\n",
        "\n",
        "### Conjunto de dados (diagnóstico) de câncer de mama em Wisconsin\n",
        "--------------------------------------------\n",
        "\n",
        "**Características do Data Set:**\n",
        "\n",
        "    :Número de instâncias: 569\n",
        "\n",
        "    :Número de atributos: 30 atributos numéricos preditivos e a classe\n",
        "\n",
        "    :Informações dos atributos:\n",
        "        - radius (média das distâncias do centro aos pontos do perímetro)\n",
        "        - texture (desvio padrão dos valores da escala de cinza)\n",
        "        - perimeter\n",
        "        - area\n",
        "        - smoothness (variação local no comprimento do raio)\n",
        "        - compactness (perímetro^2 / área - 1.0)\n",
        "        - concavity (gravidade das porções côncavas do contorno)\n",
        "        - concave points (número de porções côncavas do contorno)\n",
        "        - symmetry \n",
        "        - fractal dimension (\"aproximação da costa\" - 1)\n",
        "\n",
        "        A média, erro padrão e \"pior\" ou maior (média dos três maiores valores) desses atributos foram computados para cada imagem, resultando em 30 características. Por exemplo, o campo 3 é o raio médio, o campo\n",
        "        13 é o Raio EP (SE standard error), o campo 23 é o Pior Raio.\n",
        "\n",
        "        - classe:\n",
        "                - WDBC-Malignant\n",
        "                - WDBC-Benign\n",
        "\n",
        "    :Estatísticas resumidas:\n",
        "\n",
        "    ===================================== ====== ======\n",
        "                                           Min    Max\n",
        "    ===================================== ====== ======\n",
        "    radius (mean):                        6.981  28.11\n",
        "    texture (mean):                       9.71   39.28\n",
        "    perimeter (mean):                     43.79  188.5\n",
        "    area (mean):                          143.5  2501.0\n",
        "    smoothness (mean):                    0.053  0.163\n",
        "    compactness (mean):                   0.019  0.345\n",
        "    concavity (mean):                     0.0    0.427\n",
        "    concave points (mean):                0.0    0.201\n",
        "    symmetry (mean):                      0.106  0.304\n",
        "    fractal dimension (mean):             0.05   0.097\n",
        "    radius (standard error):              0.112  2.873\n",
        "    texture (standard error):             0.36   4.885\n",
        "    perimeter (standard error):           0.757  21.98\n",
        "    area (standard error):                6.802  542.2\n",
        "    smoothness (standard error):          0.002  0.031\n",
        "    compactness (standard error):         0.002  0.135\n",
        "    concavity (standard error):           0.0    0.396\n",
        "    concave points (standard error):      0.0    0.053\n",
        "    symmetry (standard error):            0.008  0.079\n",
        "    fractal dimension (standard error):   0.001  0.03\n",
        "    radius (worst):                       7.93   36.04\n",
        "    texture (worst):                      12.02  49.54\n",
        "    perimeter (worst):                    50.41  251.2\n",
        "    area (worst):                         185.2  4254.0\n",
        "    smoothness (worst):                   0.071  0.223\n",
        "    compactness (worst):                  0.027  1.058\n",
        "    concavity (worst):                    0.0    1.252\n",
        "    concave points (worst):               0.0    0.291\n",
        "    symmetry (worst):                     0.156  0.664\n",
        "    fractal dimension (worst):            0.055  0.208\n",
        "    ===================================== ====== ======\n",
        "\n",
        "    :Valores de atributos ausentes: None\n",
        "\n",
        "    :Distribuição de classes: 212 - Malignant, 357 - Benign\n",
        "\n",
        "    :Criador:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
        "\n",
        "    :Doador: Nick Street\n",
        "\n",
        "    :Data: November, 1995\n",
        "\n",
        "Esta é uma cópia do UCI ML Breast Cancer Wisconsin (Diagnostic) dataset.\n",
        "https://goo.gl/U2Uwz2\n",
        "\n",
        "As características são calculadas a partir de uma imagem digitalizada de uma fine needle aspirate (FNA) de uma massa mamária. Eles descrevem características dos núcleos celulares presentes na imagem.\n",
        "\n",
        "O plano de separação descrito acima foi obtido usando Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], um método de classificação que usa programação linear para construir uma árvore de decisão. Características relevantes foram selecionados usando uma busca exaustiva no espaço de 1-4 características e 1-3 planos de separação.\n",
        "\n",
        "O programa linear real usado para obter o plano de separação no espaço tridimensional é o descrito em: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\",\n",
        "Optimization Methods and Software 1, 1992, 23-34].\n",
        "\n",
        "Esse banco de dados também está disponível por meio do servidor UW CS ftp:\n",
        "\n",
        "ftp ftp.cs.wisc.edu\n",
        "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
        "\n",
        ".. tópico:: Referências\n",
        "\n",
        "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993.\n",
        "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and prognosis via linear programming. Operations Research, 43(4), pages 570-577, July-August 1995.\n",
        "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) 163-171."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgHyCxRQzkCW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"drive/My Drive/Colab Notebooks/IA/21_ANNs\")\n",
        "os.listdir()"
      ],
      "metadata": {
        "id": "Gw9I2O8iz-ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE2_eUHUzkCZ"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('DATA/cancer_classification.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muGMJf-lzkCb"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAVRkmxWzkCd"
      },
      "outputs": [],
      "source": [
        "df.describe().transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIorYDEKzkCe"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWEvOR1SzkCe"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--zquPIczkCf"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x='benign_0__mal_1',data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_2YfButzkCg"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(df.corr())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dD2uGxNEzkCg"
      },
      "outputs": [],
      "source": [
        "df.corr()['benign_0__mal_1'].sort_values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UebWqjrrzkCh"
      },
      "outputs": [],
      "source": [
        "df.corr()['benign_0__mal_1'].sort_values().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ak19G9HGzkCi"
      },
      "outputs": [],
      "source": [
        "df.corr()['benign_0__mal_1'][:-1].sort_values().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tiPpzkFzkCi"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWxwLsTWzkCj"
      },
      "outputs": [],
      "source": [
        "X = df.drop('benign_0__mal_1',axis=1).values\n",
        "y = df['benign_0__mal_1'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFet15YrzkCj"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMQInXc0zkCk"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=101)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5VTqk7yzkCk"
      },
      "source": [
        "## Dimensionando os dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqfnTgTyzkCk"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYlWb94gzkCl"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yc0bZnP-zkCl"
      },
      "outputs": [],
      "source": [
        "scaler.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E40ER-hLzkCm"
      },
      "outputs": [],
      "source": [
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPlLV5R3zkCn"
      },
      "source": [
        "## Criando o modelo\n",
        "\n",
        "    # Para um modelo de classificação binária\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "                  \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuIMMYZUzkCn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation,Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udLd6XyWzkCo"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJ7N-_FLzkCp"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
        "\n",
        "model.add(Dense(units=30,activation='relu'))\n",
        "\n",
        "model.add(Dense(units=15,activation='relu'))\n",
        "\n",
        "\n",
        "model.add(Dense(units=1,activation='sigmoid'))\n",
        "\n",
        "#Para um modelo de classificação binária\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AESwxVWZzkCq"
      },
      "source": [
        "## Treinando o Modelo \n",
        "\n",
        "### Exemplo Um: Escolhendo muitas épocas e overfitting!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHD_qP4qzkCr"
      },
      "outputs": [],
      "source": [
        "# https://stats.stackexchange.com/questions/164876/tradeoff-batch-size-vs-number-of-iterations-to-train-a-neural-network\n",
        "# https://datascience.stackexchange.com/questions/18414/are-there-any-rules-for-choosing-the-size-of-a-mini-batch\n",
        "\n",
        "model.fit(x=X_train, \n",
        "          y=y_train, \n",
        "          epochs=600,\n",
        "          validation_data=(X_test, y_test), verbose=1\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaZY6JXqzkCt"
      },
      "outputs": [],
      "source": [
        "# model.history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmVYmjQnzkCu"
      },
      "outputs": [],
      "source": [
        "model_loss = pd.DataFrame(model.history.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9O67AzszkCu"
      },
      "outputs": [],
      "source": [
        "# model_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvP-_07OzkCv"
      },
      "outputs": [],
      "source": [
        "model_loss.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2E1fcSWIzkCv"
      },
      "source": [
        "## Exemplo Dois: Parada Antecipada\n",
        "\n",
        "Obviamente treinamos demais! Vamos usar a parada antecipada para rastrear o val_loss e parar de treinar assim que começar a aumentar demais!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYFqNuUPzkCw"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(units=30,activation='relu'))\n",
        "model.add(Dense(units=15,activation='relu'))\n",
        "model.add(Dense(units=1,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxPt4EgDzkCw"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa8VwL2szkCx"
      },
      "source": [
        "Pare de treinar quando uma quantidade monitorada parar de melhorar.\n",
        "\n",
        "    Argumentos:\n",
        "        monitor: Quantidade a ser monitorada.\n",
        "        min_delta: Mudança mínima na quantidade monitorada para se qualificar como uma melhoria, ou seja, uma alteração absoluta menor que min_delta, não contará como melhoria.\n",
        "        patience: Número de épocas sem melhora após as quais o treinamento será interrompido.\n",
        "        verbose: modo verbosidade.\n",
        "        mode: Um entre `{\"auto\", \"min\", \"max\"}`. No modo `min`, o treinamento irá parar quando a quantidade monitorada parar de diminuir; no modo `max` ele irá parar quando a quantidade monitorada parar de aumentar; no modo `auto`, a direção é inferida automaticamente a partir do nome da quantidade monitorada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDIGTPAOzkCx"
      },
      "outputs": [],
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmA_gDtqzkCx"
      },
      "outputs": [],
      "source": [
        "model.fit(x=X_train, \n",
        "          y=y_train, \n",
        "          epochs=600,\n",
        "          validation_data=(X_test, y_test), verbose=1,\n",
        "          callbacks=[early_stop]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMgE45rxzkCy"
      },
      "outputs": [],
      "source": [
        "model_loss = pd.DataFrame(model.history.history)\n",
        "model_loss.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKWrGt5SzkCz"
      },
      "source": [
        "## Exemplo Três: Adicionando DropOut Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xqh_3HL2zkCz"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZRgp5HMzkC0"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(units=30,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(units=15,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(units=1,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DD7_gvtuzkC0"
      },
      "outputs": [],
      "source": [
        "model.fit(x=X_train, \n",
        "          y=y_train, \n",
        "          epochs=600,\n",
        "          validation_data=(X_test, y_test), verbose=1,\n",
        "          callbacks=[early_stop]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wu0B0V1QzkC1"
      },
      "outputs": [],
      "source": [
        "model_loss = pd.DataFrame(model.history.history)\n",
        "model_loss.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-2wp4-2zkC2"
      },
      "source": [
        "# Avaliação do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFO0SLp5zkC2"
      },
      "outputs": [],
      "source": [
        "predictions = (model.predict(X_test) > 0.5).astype(\"int32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UicG-KE1zkC2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVL1B1QVzkC3"
      },
      "outputs": [],
      "source": [
        "# https://en.wikipedia.org/wiki/Precision_and_recall\n",
        "print(classification_report(y_test,predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ET7OGrwCzkC3"
      },
      "outputs": [],
      "source": [
        "print(confusion_matrix(y_test,predictions))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}